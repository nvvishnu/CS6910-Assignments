{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMK+DU7njLPBV2ok8EIUrXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvvishnu/CS6910-Assignments/blob/main/Assignment2/partA/Assignment2_partA_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6y6344Ixh9y",
        "outputId": "dc515940-9571-473d-fe51-9eb20335e8dd"
      },
      "source": [
        "from tensorflow.keras import *\n",
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/5d/20ab24504de2669c9a76a50c9bdaeb44a440b0e5e4b92be881ed323857b1/wandb-0.10.26-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.7MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 27.5MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=0c097f2efd709e23b6e2ee7a4da853ebf142eefb3b88d24d032bc854cd38610d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=0130dfe218ff42edc4576909097bd9f5225ec71fa3c127a257f3541110b4a7c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: shortuuid, sentry-sdk, smmap, gitdb, GitPython, docker-pycreds, configparser, pathtools, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrbWkZtvy4RI",
        "outputId": "fbe742af-6f15-4a59-a32e-fb8c7171871d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gUIvbhpzad6"
      },
      "source": [
        "# Splitting training data into training and validation set in the ratio 9:1 \n",
        "\n",
        "# # import os\n",
        "# # path = '/content/drive/MyDrive/nature_12K.zip'\n",
        "# # import zipfile\n",
        "# # with zipfile.ZipFile(path, 'rw') as zip_ref:\n",
        "# #     zip_ref.extractall('/content/drive/MyDrive/Assignment2')\n",
        "# !pip install split-folders tqdm\n",
        "# import splitfolders\n",
        "# splitfolders.ratio(path+'train', output=path+'split', seed=1337, ratio=(.9, .1), group_prefix=None) # default values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJbgq06Zy9qg"
      },
      "source": [
        "path = '/content/drive/MyDrive/Assignment2/inaturalist_12K/' #Load the inaturalist_12K dataset\n",
        "\n",
        "##simple function which returns the CNN consisting of 5 convolution layers\n",
        "#filters is a list , where filters[i] indicates num of filters in ith convolutional layer (0 indexing)\n",
        "#kern_filter is a list of tuples denoting the kernel_size of the filter\n",
        "#actiavation_fn is a list of activation functions\n",
        "\n",
        "def simplenetwork(filters,kern_filter,activation_fn,dense_layer_size):\n",
        "    model = Sequential()\n",
        "    for i in range(5):\n",
        "          if(i == 0):\n",
        "            model.add(layers.Conv2D(filters[i],kern_filter[i],input_shape=(224,224,3),activation=activation_fn[i]))     \n",
        "          else :\n",
        "            model.add(layers.Conv2D(filters[i],kern_filter[i],activation=activation_fn[i]))\n",
        "          model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(dense_layer_size,activation=activation_fn[5]))\n",
        "    model.add(layers.Dense(10,activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzDstdrvzBiZ",
        "outputId": "31dc5ca5-0849-4ea0-8a3f-f975f4462d03"
      },
      "source": [
        "model = simplenetwork([32,32,32,32,32],[(3,3),(3,3),(3,3),(3,3),(3,3)],['relu' for i in range(6)],1024)\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 109, 109, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 54, 54, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 52, 52, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              820224    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 868,362\n",
            "Trainable params: 868,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9MNV5uvzERx"
      },
      "source": [
        "#More general function where we can add drop_out batch_normalisation , avg_pool etc.\n",
        "#filters is a list , where filters[i] indicates num of filters in ith convolutional layer (0 indexing)\n",
        "#kern_filter is a list of tuples denoting the kernel_size of the filter\n",
        "#actiavation_fn is a list of activation functions\n",
        "#drop_out is the value of drop_out we will apply\n",
        "#batch_normalisation if set true we do batch normalisation after each layer\n",
        "#dense_layer is the size of dense layer\n",
        "#train is train data\n",
        "#validation is validation data\n",
        "#num_classes is the number of output classes , this case we pass 10\n",
        "#epochs is number of epochs\n",
        "#drop_batch_dense , if 'both' then we apply dropout followed by batchnormalisation after dense layer , if set 'batch' we do only batch_normalisation after dense layer and if ser 'drop' we apply dropout after dense layer\n",
        "#last2avg_pool if set true then for last2 Convolutional layers we do avgpool instead of maxpooling\n",
        "#dp_after_each CNN , if set true then we apply dropout after every ConV layer else we apply dropout only on last2 convolutional layers\n",
        "\n",
        "def network(filters,kern_filter,activation_fn,drop_out,batch_normalisation,dense_layer,train,validation,num_classes,epochs,drop_batch_dense,last_2_avgpool,dp_aft_eachCNN):\n",
        "    \n",
        "     model = Sequential()\n",
        "     \n",
        "     if (batch_normalisation):\n",
        "        for i in range(5):\n",
        "          if(i == 0):\n",
        "            model.add(layers.Conv2D(filters[i],kern_filter[i],input_shape=(224,224,3),activation=activation_fn[i]))     \n",
        "          else :\n",
        "            model.add(layers.Conv2D(filters[i],kern_filter[i],activation=activation_fn[i]))\n",
        "\n",
        "          if (i<=2 or not(last_2_avgpool)):\n",
        "             if(dp_aft_eachCNN or i>2):\n",
        "                model.add(layers.Dropout(drop_out))\n",
        "             model.add(layers.BatchNormalization())\n",
        "             model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "          else:\n",
        "             model.add(layers.Dropout(drop_out))\n",
        "             model.add(layers.BatchNormalization())\n",
        "             model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "     else:\n",
        "        for i in range(5):\n",
        "          if(i == 0):\n",
        "            model.add(layers.Conv2D(filters[i],kern_filter[i],input_shape=(224,224,3),activation=activation_fn[i]))\n",
        "          else :\n",
        "            model.add(layers.Conv2D(filters[i],kern_filter[i],activation=activation_fn[i]))\n",
        "          if(i<=2 or not(last_2_avgpool)):\n",
        "             if(i>2 or dp_aft_eachCNN):\n",
        "               model.add(layers.Dropout(drop_out))\n",
        "             model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "          else:\n",
        "             model.add(layers.Dropout(drop_out))\n",
        "             model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "     model.add(layers.Flatten())\n",
        "     model.add(layers.Dropout(drop_out))\n",
        "     model.add(layers.BatchNormalization())\n",
        "     model.add(layers.Dense(dense_layer,activation='relu'))  #activation_fn[5]))\n",
        "     if(drop_batch_dense == 'both' or drop_batch_dense == 'drop'):\n",
        "         model.add(layers.Dropout(drop_out))\n",
        "     if(drop_batch_dense == 'both' or drop_batch_dense == 'batch'):\n",
        "         model.add(layers.BatchNormalization())\n",
        "     model.add(layers.Dense(num_classes))\n",
        "     model.add(layers.Softmax())\n",
        "     labels = ['Amphibia','Animalia','Arachnida','Aves','Fungi','Insecta','Mammalia','Mollusca','Plantae','Reptilia']\n",
        "     print(model.summary())\n",
        "\n",
        "     model.compile(optimizer='adam',loss=losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "     model.fit(train,epochs=epochs,validation_data=validation,callbacks=[WandbCallback()])\n",
        "\n",
        "     return model"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}